# ğŸ¬ AI-Powered Video Scene & Emotion Analysis  

## ğŸ“Œ Overview  
This project was developed during my internship at **Visatsy** in collaboration with the **Ã‰cole Polytechnique de Tunisie**.  
It focuses on building an **AI-powered video analysis system** that performs **scene segmentation, visual understanding, and emotion recognition**.  
The final goal is to enable intelligent **video recommendation, mental health analysis, and advanced emotion-aware retrieval systems**.  

---

## ğŸš€ Objectives  
- Segment videos into **meaningful scenes** using shot boundary detection.  
- Extract **keyframes** that best represent each scene.  
- Detect **objects, faces, and gestures** using state-of-the-art models.  
- Perform **emotion recognition** via facial expressions and heuristic cues.  
- Generate **descriptive captions** for each scene using multimodal models.  
- Store embeddings for **semantic search & retrieval** (RAG-based).  
- Provide an intuitive **dashboard/UI** for visualization and interaction.  

---

## ğŸ”§ Use Cases  
1. **ğŸ¥ Recommendation Systems** â€“ Suggest videos or clips based on detected themes, moods, or objects.  
2. **ğŸ§  Mental Health Analysis** â€“ Identify emotional states (stress, depression, anxiety, etc.) from video interactions.  
3. **ğŸ˜Š Emotion Analysis** â€“ Track charactersâ€™ emotional evolution across a film, series, or recorded session.  

---

## ğŸ› ï¸ Tech Stack  
- **Scene Captioning:** BLIP / BLIP-2  
- **Object Detection:** YOLOv8
- **Face Detection & Emotion:** DeepFace + MediaPipe heuristics  
- **Scene-Level Labeling:** Gemini LLMs (RAG pipeline)  
- **Vector Search:** ChromaDB   
- **Frontend:** Gradio  



---

## ğŸ“‚ Project Structure  
